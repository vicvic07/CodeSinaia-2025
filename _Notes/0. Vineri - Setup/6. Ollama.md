Friday: 10:00 - 12:00
Resources: [Ollama](https://ollama.com/download)

- [ ] Download [Ollama](https://ollama.com/download). Verify installation is successful from a command window, typing the following:
    ```
    > ollama
    Usage:
      ollama [flags]
      ollama [command]
      [...]
    ```
- [ ] Download a [model](https://github.com/ollama/ollama). Scroll down to the **Model Library** section to select an AI model that fits your computer's spec. If unsure, go with the smallest you see, i.e. "**Gemma 3**" has 1 billion parameters and requires 815Mb of disk storage on your system. From a command window, run the following:
    ```
    > ollama pull gemma3:1b
    ```
   The model is downloaded in your user's profile:

|  Windows   | C:\Users\YourName\.ollama\models |
| --------- | -------------------------------- |
| Linux/Mac | ~/.ollama/models                 |

   To manage the models (since they consume significant storage on your computer) you can use the following commands:

    ```
    > ollama list
    NAME         ID              SIZE      MODIFIED
    gemma3:1b    8648f39daa8f    815 MB    24 minutes ago

    > ollama rm gemma3:1b
    deleted 'gemma3:1b'
    ```
   If you have to ^C a model while downloading, is likely files are left orphaned - nothing bad other than wasting space on your disk. To clean out the model fully go to file explorer and delete the content of the models folder

- [ ] Verify everything works end-to-end. Still in command window run the following command (by using the name of the model you downloaded):

    ```
    > ollama run gemma3:1b
    >>> Hi there!
    Hi there to you too! How's your day going so far? ðŸ˜Š

    Is there anything youâ€™d like to chat about or need help with?

    >>> /bye
    > 
    ```
